<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> POMDP Planning for Problems with Complex Dynamics | Robust Decision Making Lab </title> <meta name="author" content="You R. Name"> <meta name="description" content="Many POMDP (Partially Observable Markov Decision Process) solvers that can compute good approximate solutions on-line have been proposed. Some of them can even find good solutions in near real-time for several realistic problems. In this project, we aim to make on-line POMDP solvers more tractable for systems with complex non-linear dynamics."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rafisudrajat.github.io/projects/1_project_rdl/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <img src="/assets/img/rdl_logo.png?11e5b2abd7dfd8659b915ab84202c2be" class="img-fluid" style="height: 60px;" alt=""> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/software/">software </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">contact </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Pomdp planning for problems with complex dynamics</h1> </header> <article> <p class="text-justify"> Many POMDP (Partially Observable Markov Decision Process) solvers that can compute good approximate solutions on-line have been proposed. Some of them can even find good solutions in near real-time for several realistic problems. Despite these advances, they perform poorly when the dynamics of the POMDP agent is non-linear and complex (i.e., has no closed-form solution). To compute a strategy, most state-of-the-art on-line solvers rely on a large number of forward simulations to evaluate sequences of actions from different beliefs. For robots with complex non-linear dynamics where even a single forward simulation requires expensive numerical integrations, this strategy quickly becomes infeasible, as indicated in the results </p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_img/complex_dynamics/fig1-480.webp 480w,/assets/img/project_img/complex_dynamics/fig1-800.webp 800w,/assets/img/project_img/complex_dynamics/fig1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/project_img/complex_dynamics/fig1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="problem in compled dynamix" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> (a) The Rocksample problem with simple and cheap transition dynamics. (b) The KukaOffice problem with complex and expensive non-linear transition dynamics. (c) The cost of forward-simulations in both problems (in percentage of the total planning cost). </div> <p class="text-justify"> In this project, we aim to make on-line POMDP solvers more tractable for systems with complex non-linear dynamics. Our methods are motivated by two key insights: </p> <ol type="1"> <li>Using cheaper, less accurate dynamic models is often sufficient to compute good policies.</li> <li>Coarse, low-fidelity models can be combined with accurate, high-fidelity models to reduce the cost of sampling while maintaining correctness.</li> </ol> <p class="text-justify"> Based on these insights we show how systematic approximations of complex, non-linear transition dynamics can be used to design on-line POMDP solvers that are more efficient than current state-of-the-art solvers. </p> <h2> Problem simplification via linearization </h2> <p class="text-justify"> Linearization is a common practice in solving non-linear control and estimation problems. However, it is known that linearization only works well for systems with mild non-linearities and small uncertainties. Additionally, it is not clear how linearized models affect the quality of the computed policy, and more importantly, when such a simplification is admissible. To answer these questions, we developed a novel measure of non-linearty for stochastic systems called <strong>Statistical Distance-based Non-linearity measure (SNM)</strong>. Intuitively, SNM is based on the distance between the distributions that represent the original motion-sensing models and their linearized version. We showed that the value difference of the optimal policy for the original model and the optimal policy for the linearized model can be upper-bounded by a function that is linear in SNM. Furthermore, extensive experimental evaluations indicate that SNM is more effective in measuring the effects obstacles have on non-linearity of a system compared to an extisting state-of-the-art measure of non-linearity. We then developed an on-line POMDP solver, called <strong>SNM-Planner</strong>, that uses SNM as a heuristic to decide when a linearization-based should be used for the policy computation and when a general solver should be used. We tested SNM-Planner on a number of motion-planning problems under uncertainty involving robots with non-linear transition dynamics. By combining a general solver and a linearization-based solver, SNM-Planner can compute more robust policies compared to each of the component solvers alone. Details of SNM and SNM-Planner results can be viewed <a target="_blank" href="/assets/pdf/papers/wafr16_linearization.pdf">here</a>. </p> <h2> Multilevel Monte-Carlo applied to POMDP planning </h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_img/complex_dynamics/fig2-480.webp 480w,/assets/img/project_img/complex_dynamics/fig2-800.webp 800w,/assets/img/project_img/complex_dynamics/fig2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/project_img/complex_dynamics/fig2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example scenario for POMDP evaluation" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Test scenarios used to evaluate MLPP </div> <p class="text-justify"> Inspired by our second key insight, we developed a new on-line POMDP solver called Multilevel POMDP Planner (MLPP). MLPP combines the commonly used Monte-Carlo-Tree-Search with a recent concept in Monte-Carlo, called Multilevel Monte-Carlo (MLMC). MLMC is a variance reduction technique that uses cheap and coarse approximations to the system to carry out the majority of the simulations, and combines them with a small number of accurate but expensive simulations to maintain correctness. By constructing a set of correlated samples from a sequence of approximations to the original system’s dynamics, in conjunction with applying Multilevel Monte-Carlo estimation to compute the expected value of sequences of actions, MLPP can compute near-optimal policies substantially faster (up to 10x) than some of today's fastest on-line solvers on four challenging robot motion planning under uncertainty problems. Details of the results are available <a target="_blank" href="/assets/pdf/papers/isrr19_mlmc.pdf">here</a>. </p> <p> </p> <h2> References </h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Hoe22:Multilevel" class="col-sm-8"> <div class="title">Multilevel Monte-Carlo for Solving POMDPs Online</div> <div class="author"> M. Hoerger, H. Kurniawati, and A. Elfes </div> <div class="periodical"> <em>International Journal of Robotics Research (IJRR)</em>, 2022 </div> <div class="periodical"> To appear </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/papers/ijrr22_mlmc.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Hoe22:Multilevel</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multilevel Monte-Carlo for Solving POMDPs Online}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Robotics Research (IJRR)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoerger, M. and Kurniawati, H. and Elfes, A.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{To appear}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Hoe16:Linearization" class="col-sm-8"> <div class="title">Linearization in Motion Planning under Uncertainty</div> <div class="author"> M. Hoerger, H. Kurniawati, T. Bandyopadhyay, and A. Elfes </div> <div class="periodical"> <em>In Proc. Int. Workshop on The Algorithmic Foundations of Robotics (WAFR)</em>, 2016 </div> <div class="periodical"> including supplementary materials </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/papers/wafr16_linearization.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Hoe16:Linearization</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoerger, M. and Kurniawati, H. and Bandyopadhyay, T. and Elfes, A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Linearization in Motion Planning under Uncertainty}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Int. Workshop on The Algorithmic Foundations of Robotics (WAFR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{including supplementary materials}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <h2> People </h2> <ul> <li>Marcus Hoerger</li> <li>Hanna Kurniawati</li> <li>Alberto Elfes</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Robust Decision Making Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@latest/tabler-icons.min.css"> </html>